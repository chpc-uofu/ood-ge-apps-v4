#!/usr/bin/env bash

################################################################################
# Environment Modules
################################################################################

# module load <%#= context.python %>
# additional environment
<%- if context.additional_environment != "" -%>
  <%= context.additional_environment.gsub /\r\n?/, "\n" %>
<%- end -%>
module load apptainer/1.4.1
mkdir -p <%= context.scratch_dir %>

# launch Ollama - theoretically we don't need the & at the end since this is a separate job now.
unset APPTAINER_BINDPATH
#Need to create config.yaml file for security and ease of editing later
if [ -e ${ollama_models}${ollama_model}/chat_template.jinja ]; then
cat > vllm_config.yaml <<EOL
model: ${ollama_models}${ollama_model}
host: 0.0.0.0
port: $port
chat-template: ${ollama_models}${ollama_model}/chat_template.jinja
api-key: $VLLM_API_KEY
EOL
else
cat > vllm_config.yaml <<EOL
model: ${ollama_models}${ollama_model}
host: 0.0.0.0
port: $port
api-key: $VLLM_API_KEY
EOL
fi
apptainer run --nv -e --fakeroot --env HF_HOME=/root/.cache/ --bind /scratch/general/vast/u6040150/vllm_cache:/root/.cache,/scratch/general/vast/app-repo/huggingface /uufs/chpc.utah.edu/sys/installdir/r8/vllm/vllm_current_cuda_sif_link --config vllm_config.yaml >& llm.log

