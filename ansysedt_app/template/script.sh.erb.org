#!/usr/bin/env bash

#<%- gpu = context.node_type.include?("vis") -%>

env |grep SLURM

# Clean the environment
module purge

# Set working directory to home directory
cd "${HOME}"

#
# Launch Xfce Window Manager and Panel
#

(
  module restore
  export XDG_CONFIG_HOME="<%= session.staged_root.join("config") %>"
  export XDG_DATA_HOME="<%= session.staged_root.join("share") %>"
  export XDG_CACHE_HOME="$(mktemp -d)"
  xfwm4 --compositor=off --daemon --sm-client-disable
  xsetroot -solid "#D3D3D3"
  xfsettingsd --sm-client-disable
  xfce4-panel --sm-client-disable
) &

#
# Start ANSYS Workbench
#

# Load the required environment
module load intel # for Intel MPI
module load <%= context.version %>

# Another ANSYS job with the same job name (file) is already running in this
# directory or the file.lock file has not been deleted from an abnormally
# terminated ANSYS run.  To disable this check, set the ANSYS_LOCK environment
# variable to OFF.
export ANSYS_LOCK="OFF"

#
# CFX Related Options
#

<%- unless gpu -%>
# Disable hardware rendering mode
export CUE_GRAPHICS="mesa"
<%- end -%>

# Fix bug when running Intel MPI code on OSC
export I_MPI_PMI_EXTENSIONS=on

# Add custom "OSC MPI" as a start method
export CFX5_START_METHODS_CCL="<%= session.staged_root.join("cfx_assets", "start-methods.ccl") %>"

# Make a hosts file that CFX will use in Parallel Distributed
export SLURM_NODEFILE="${HOME}/.cfx/nodes.${SLURM_JOBID}"
srun hostname -s | sort > $SLURM_NODEFILE 
mkdir -p "${HOME}/.cfx"
export CFX5_HOSTS_CCL="${HOME}/.cfx/hostinfo.${SLURM_JOBID}"
NODES=$(tr '\n' ',' < "${SLURM_NODEFILE}" | sed -e 's/ /,/g')
NODES=${NODES%?}
touch "${CFX5_HOSTS_CCL}"
cfx5parhosts -add "${NODES}" -user -file "${CFX5_HOSTS_CCL}"

# TEST
cp ${CFX5_HOSTS_CCL} ${CFX5_HOSTS_CCL}.org

# Only give OSC MPI option to user through GUI
HOSTINFO=$(head -n -2 "${CFX5_HOSTS_CCL}")
cat > "${CFX5_HOSTS_CCL}" << EOL
${HOSTINFO}
    SOLVER STEP CONTROL:
      Runtime Priority = Standard
      MEMORY CONTROL:
        Memory Allocation Factor = 1.0
      END
      PARALLEL ENVIRONMENT:
        Parallel Host List = ${NODES}
        Start Method = CHPC Intel MPI Distributed Parallel
      END
    END
  END # EXECUTION CONTROL
END # SIMULATION CONTROL
EOL

#
# RSH & SSH wrappers
#

# Add RSH and SSH wrappers for Fluent and CFX
# don't need those ...
# export PATH="<%= session.staged_root.join("bin") %>:${PATH}"

# Launch ANSYS Workbench
#<%- if gpu -%>
#module load intel/16.0.3 virtualgl
#module list
#set -x
#vglrun runwb2
#<%- else -%>
module list
set -x
runwb2
#<%- end -%>
