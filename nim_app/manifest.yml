---
name: Nvidia Inference Microservice with Jupyter
category: Interactive Apps
subcategory: Servers
role: batch_connect
description: |
  This app will launch a selected Nvidia Inference Microservice ([NIM] in a [Jupyter] Notebook or Lab server using [Python] on a [HPC
  cluster] or on a [Frisco node]. See [example notebooks] for basic functionality.

  NOTE: You need to use your own [NGC API key]. Choose appropriate resources for the chosen NIM (TBD). Most need a GPU.
 
  To start the job promptly, use notchpeak-shared-short account and partition on the [Notchpeak cluster].

  [GPU specification] is optional for the clusters and partitions that have them.

  [NGC API key]: https://docs.nvidia.com/ai-enterprise/deployment/spark-rapids-accelerator/latest/appendix-ngc.html
  [example notebooks]: https://github.com/chpc-uofu/ood-ge-apps-v4/tree/main/nim_app/example
  [NIM]: https://developer.nvidia.com/nim
  [RFDiffusion]: https://docs.nvidia.com/nim/bionemo/rfdiffusion/latest/overview.html
  [Jupyter]: https://jupyter.org/
  [Python]: https://www.python.org/
  [HPC cluster]: https://www.chpc.utah.edu/resources/HPC_Clusters.php
  [GPU specification]: https://www.chpc.utah.edu/documentation/guides/gpus-accelerators.php#overview
  [Frisco node]: https://www.chpc.utah.edu/documentation/guides/frisco-nodes.php
  [Notchpeak cluster]: https://www.chpc.utah.edu/documentation/policies/2.1GeneralHPCClusterPolicies.php#Pol2.1.6

